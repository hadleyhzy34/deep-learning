{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## The vanishing/exploding gradients problems"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the vanishing gradients:\n",
    "gradients often get smaller and smaller as the algorithm progresses down to the lowe layers.As the result, the gradient descent update leaves the lower layers' connection weights virtually uncahgned, and training never converges to a good solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploding gradients:\n",
    "the gradients can grow bigger and bigger until layers get insanely large weight updates and the algorithm diverges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic sigmoid activation function+ weight, normal distribution with a mean of 0 and a standard deviation of 1:\n",
    "the variance of output layer ism uch greater than the variance of its inputs. when output is very large, the sigmoid function saturates at 0 or 1, with a derivative extremely close to 0. when backpropagation kicks in it has virtually no gradient to propagate back through the network. "
   ]
  },
  {
   "source": [
    "### Xavier/Glorot initialization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.variance of output layer and input layer must be equal to each other\n",
    "2.variance of gradients before and after flow through a layer\n",
    "\n",
    "=>solution: the layer has an equal number of inputs and neurons\n",
    "for each layer(fanin: number of inputs and previous layers neurons, fanout: number of outputs and current layers' neurons)\n",
    "\n",
    "=>compromise: connection weights of each layer must be initialized randomly based on equation:\n",
    "1.normal distribution with mean 0 and variance sigma square equals to 1/fan_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he initialization:\n",
    "As we showed before, keeping the standard deviation of layers’ activations around 1 will allow us to stack several more layers in a deep neural network without gradients exploding or vanishing.\n",
    "This exploration into how to best initialize weights in networks with ReLU-like activations is what motivated Kaiming He et. al. to propose their own initialization scheme that’s tailored for deep neural nets that use these kinds of asymmetric, non-linear activations.\n",
    "In their 2015 paper, He et. al. demonstrated that deep networks (e.g. a 22-layer CNN) would converge much earlier if the following input weight initialization strategy is employed:\n",
    "Create a tensor with the dimensions appropriate for a weight matrix at a given layer, and populate it with numbers randomly chosen from a standard normal distribution.\n",
    "Multiply each randomly chosen number by √2/√n where n is the number of incoming connections coming into a given layer from the previous layer’s output (also known as the “fan-in”).\n",
    "Bias tensors are initialized to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReLU functions => leaky functions(LeakyReLU)\n",
    "=> randomized leaky ReLU(RReLU)\n",
    "=> parametric leaky ReLU(PReLU)\n",
    "=> exponential linear unit(ELU)\n",
    "=> scaled ELU(SELU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Batch Normalization\n",
    "\n",
    "adding an operation before or after the activation function of each hidden layer. zero-centers and normalizes each input, then scales and shifts the result using two new parameter vectors per layer. the operation lets the model learn the optimal scale and eman of each of the layer's inputs.\n",
    "\n",
    "batch normalization moving average???"
   ]
  },
  {
   "source": [
    "## Faster Optimizers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### momentum optimization\n",
    "\n",
    "* How to initialize the momentum value?\n",
    "* why the terminal velocity is equal to that gradient multiplied by the learning rate multiplied by 1/(1-ß). For example, if beta equals to 0.9, then the terminal velocity is equal to 10 times the gradient times the learning rate, so momentum optimization to escape from plateaus much faster than gradient descent.\n",
    "\n",
    "Anwser:\n",
    "https://stats.stackexchange.com/questions/470296/what-is-the-maximum-size-of-weights-update-in-momentum-optimisation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Nesterov Accelerated gradient\n",
    "\n",
    "the Nesterov update ends up slitly closer to the optimum. after a while, these small improvements add up and NAG ends up being significantly faster than regular momentum optimization. Moreover, note that when the momentum pushes the weights across a valley, gradient 1 continues to push farther across the valley, while gradient 2 pushes back toward the bottom of the valley. this helps reduce oscillations and thus NAG converges faster."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### AdaGrad"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### RMSProp\n",
    "p355 problem?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Adam optimization\n",
    "* exponentially decaying average, exponentially decaying sum???\n",
    "* equations???"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "unsupervised learning and auxiliary task"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning rate scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avoid overfitting through regularization\n",
    "\n",
    "1.l1 and l2 regularization"
   ]
  }
 ]
}